{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a0b21bfdedb94b3eb1f55f6bfb4c5f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77c59c69be984c3abfeea308ea1f6dbb",
              "IPY_MODEL_242b4b26bdd3470799e81069caeb3b39",
              "IPY_MODEL_e93943b1b0b14a34a4fc5b3fce328065"
            ],
            "layout": "IPY_MODEL_d8a3c28dc9d54ec0a9f84ae9980f46a3"
          }
        },
        "77c59c69be984c3abfeea308ea1f6dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b84c7cf59f6450e88421c3192cee22d",
            "placeholder": "​",
            "style": "IPY_MODEL_72003b118ca24863b7dba8816a921baf",
            "value": "Downloading: 100%"
          }
        },
        "242b4b26bdd3470799e81069caeb3b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b7e96d4493b4d1791a8bf15f7d5821d",
            "max": 3585820308,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64849a3c8b4c4c52846250f673650705",
            "value": 3585820308
          }
        },
        "e93943b1b0b14a34a4fc5b3fce328065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_def9bf25e05d4b738b36e4a12eeb320a",
            "placeholder": "​",
            "style": "IPY_MODEL_e98c8ab4f2314e0c86135e6528fae49c",
            "value": " 3.34G/3.34G [01:57&lt;00:00, 34.4MiB/s]"
          }
        },
        "d8a3c28dc9d54ec0a9f84ae9980f46a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b84c7cf59f6450e88421c3192cee22d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72003b118ca24863b7dba8816a921baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b7e96d4493b4d1791a8bf15f7d5821d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64849a3c8b4c4c52846250f673650705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "def9bf25e05d4b738b36e4a12eeb320a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e98c8ab4f2314e0c86135e6528fae49c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26b0b8e2f33849dcb332416b0f1ab86f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_452ec7cf2e864fae8fe9143f275eaeb2",
              "IPY_MODEL_2fbe9f5c5cd348ac9b9ba45723102050",
              "IPY_MODEL_6a22943843534b449eaeecdd7b7419ea"
            ],
            "layout": "IPY_MODEL_da43bee518c947aaa658371953c82ac4"
          }
        },
        "452ec7cf2e864fae8fe9143f275eaeb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_170c0f6c5f1d4cf682da6fa49f594a70",
            "placeholder": "​",
            "style": "IPY_MODEL_2b494175c6bd4b82977c45c7614fc63c",
            "value": "100%"
          }
        },
        "2fbe9f5c5cd348ac9b9ba45723102050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6c873f5a7d3445c8423348c284578fb",
            "max": 478,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14067fa5f13e4c4d8bfb2864756cc9a0",
            "value": 478
          }
        },
        "6a22943843534b449eaeecdd7b7419ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8a7363bd2f5401d92b12a5764ddd8a8",
            "placeholder": "​",
            "style": "IPY_MODEL_3e621c344a7c402facee56ce60ff12bf",
            "value": " 478/478 [03:41&lt;00:00,  1.84files/s]"
          }
        },
        "da43bee518c947aaa658371953c82ac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "170c0f6c5f1d4cf682da6fa49f594a70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b494175c6bd4b82977c45c7614fc63c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6c873f5a7d3445c8423348c284578fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14067fa5f13e4c4d8bfb2864756cc9a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8a7363bd2f5401d92b12a5764ddd8a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e621c344a7c402facee56ce60ff12bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324,
          "referenced_widgets": [
            "a0b21bfdedb94b3eb1f55f6bfb4c5f89",
            "77c59c69be984c3abfeea308ea1f6dbb",
            "242b4b26bdd3470799e81069caeb3b39",
            "e93943b1b0b14a34a4fc5b3fce328065",
            "d8a3c28dc9d54ec0a9f84ae9980f46a3",
            "6b84c7cf59f6450e88421c3192cee22d",
            "72003b118ca24863b7dba8816a921baf",
            "8b7e96d4493b4d1791a8bf15f7d5821d",
            "64849a3c8b4c4c52846250f673650705",
            "def9bf25e05d4b738b36e4a12eeb320a",
            "e98c8ab4f2314e0c86135e6528fae49c",
            "26b0b8e2f33849dcb332416b0f1ab86f",
            "452ec7cf2e864fae8fe9143f275eaeb2",
            "2fbe9f5c5cd348ac9b9ba45723102050",
            "6a22943843534b449eaeecdd7b7419ea",
            "da43bee518c947aaa658371953c82ac4",
            "170c0f6c5f1d4cf682da6fa49f594a70",
            "2b494175c6bd4b82977c45c7614fc63c",
            "e6c873f5a7d3445c8423348c284578fb",
            "14067fa5f13e4c4d8bfb2864756cc9a0",
            "e8a7363bd2f5401d92b12a5764ddd8a8",
            "3e621c344a7c402facee56ce60ff12bf"
          ]
        },
        "id": "y0mQTAe3sQLB",
        "outputId": "52fd545f-c2c9-406f-e1f0-dbd86173d145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset from Figshare (File ID: 26372272)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/3.34G [00:00<?, ?iB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0b21bfdedb94b3eb1f55f6bfb4c5f89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset...\n",
            "✓ Download and extraction complete.\n",
            "MAQAM PIPELINE STARTED at: dataset_root\n",
            "Mode: Segmentation (Max Chunk: 30.0s)\n",
            "Fix Applied: 'filename' column added for Leakage Prevention.\n",
            "Searching recursively for class folders...\n",
            "Scanning classes: ['Nahawand', 'Bayat', 'Kurd', 'Seka', 'Ajam', 'Hijaz', 'Rast', 'Saba']\n",
            "✓ Found 478 raw audio files.\n",
            "\n",
            "Starting Segmented Extraction...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/478 [00:00<?, ?files/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26b0b8e2f33849dcb332416b0f1ab86f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pipeline Finished. Extracted 924 segments from 478 files.\n",
            "✓ Final CSV has 924 rows.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0498c345-ac29-49fb-8044-d50a320bd6a8\", \"maqam_features.csv\", 1934530)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import zipfile\n",
        "import requests\n",
        "import math\n",
        "from tqdm.auto import tqdm\n",
        "from google.colab import files\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, List, Tuple, Any\n",
        "import gc\n",
        "\n",
        "# CONFIGURATION\n",
        "@dataclass\n",
        "class AudioConfig:\n",
        "    sample_rate: int = 22050\n",
        "    n_chroma: int = 24          # 24 bins for quarter tones\n",
        "    n_mfcc: int = 20            # Standard for voice/timbre\n",
        "    n_contrast_bands: int = 7   # Spectral contrast\n",
        "    min_audio_duration: float = 2.0  # Increased min duration\n",
        "    max_audio_duration: float = 30.0 # CHUNK size\n",
        "    trim_top_db: int = 20\n",
        "    cqt_bins_per_octave: int = 24\n",
        "    cqt_n_octaves: int = 7\n",
        "    hop_length: int = 1024\n",
        "    n_fft: int = 2048\n",
        "    min_valid_length: float = 0.5\n",
        "\n",
        "@dataclass\n",
        "class ProcessingConfig:\n",
        "    max_workers: int = 2 # Set to 2 for Colab stability\n",
        "\n",
        "AUDIO_CONFIG = AudioConfig()\n",
        "PROCESSING_CONFIG = ProcessingConfig()\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 1. DATASET HELPER (DOWNLOADER)\n",
        "def download_and_extract_figshare(target_dir=\"dataset_root\"):\n",
        "    \"\"\"Downloads the specific Maqam478 dataset from Figshare.\"\"\"\n",
        "    url = \"https://figshare.com/ndownloader/files/26372272\"\n",
        "    zip_path = \"maqam_dataset.zip\"\n",
        "\n",
        "    if not os.path.exists(target_dir):\n",
        "        os.makedirs(target_dir)\n",
        "\n",
        "    print(f\"Downloading dataset from Figshare (File ID: 26372272)...\")\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        total_size = int(response.headers.get('content-length', 0))\n",
        "        block_size = 1024\n",
        "\n",
        "        with open(zip_path, 'wb') as file, tqdm(\n",
        "            desc=\"Downloading\",\n",
        "            total=total_size,\n",
        "            unit='iB',\n",
        "            unit_scale=True,\n",
        "            unit_divisor=1024,\n",
        "        ) as bar:\n",
        "            for data in response.iter_content(block_size):\n",
        "                size = file.write(data)\n",
        "                bar.update(size)\n",
        "\n",
        "        print(\"Extracting dataset...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(target_dir)\n",
        "\n",
        "        os.remove(zip_path)\n",
        "        print(\"✓ Download and extraction complete.\")\n",
        "        return target_dir\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading dataset: {e}\")\n",
        "        return None\n",
        "\n",
        "# 2. DATASET PARSER\n",
        "class DatasetParser:\n",
        "    def __init__(self, root_path: str):\n",
        "        self.root_path = root_path\n",
        "\n",
        "    def find_dataset_root(self) -> str:\n",
        "        if not os.path.exists(self.root_path):\n",
        "            raise FileNotFoundError(f\"Path '{self.root_path}' not found.\")\n",
        "\n",
        "        candidate_folders = ['Bayati', 'Rast', 'Sikah', 'Ajam', 'Nahawand', 'Saba', 'Hijaz', 'Kurd']\n",
        "\n",
        "        print(\"Searching recursively for class folders...\")\n",
        "        for root, dirs, files in os.walk(self.root_path):\n",
        "            matches = [d for d in dirs if d in candidate_folders]\n",
        "            if len(matches) >= 3:\n",
        "                return root\n",
        "\n",
        "        for root, dirs, files in os.walk(self.root_path):\n",
        "            if any(f.lower().endswith(('.wav', '.mp3')) for f in files):\n",
        "                return os.path.dirname(root)\n",
        "\n",
        "        return self.root_path\n",
        "\n",
        "    def collect_audio_files(self, dataset_root: str) -> List[Tuple[str, str, str]]:\n",
        "        file_tasks = []\n",
        "        valid_extensions = ('.wav', '.mp3', '.flac', '.ogg', '.m4a')\n",
        "\n",
        "        try:\n",
        "            items = [d for d in os.listdir(dataset_root) if os.path.isdir(os.path.join(dataset_root, d))]\n",
        "        except:\n",
        "            return []\n",
        "\n",
        "        print(f\"Scanning classes: {items}\")\n",
        "        for label in items:\n",
        "            label_dir = os.path.join(dataset_root, label)\n",
        "            for f in os.listdir(label_dir):\n",
        "                if f.lower().endswith(valid_extensions):\n",
        "                    file_path = os.path.join(label_dir, f)\n",
        "                    # Create a unique ID combining Folder + Filename (e.g., \"Rast/file01.wav\")\n",
        "                    unique_id = f\"{label}/{f}\"\n",
        "                    file_tasks.append((file_path, label, unique_id))\n",
        "        return file_tasks\n",
        "\n",
        "# 3. FEATURE EXTRACTOR\n",
        "class FeatureExtractor:\n",
        "    def __init__(self, config: AudioConfig):\n",
        "        self.config = config\n",
        "\n",
        "    def extract_features(self, y: np.ndarray, sr: int) -> Optional[List[float]]:\n",
        "        try:\n",
        "            features = []\n",
        "            if len(y) < sr * self.config.min_valid_length: return None\n",
        "\n",
        "            CQT = np.abs(librosa.cqt(\n",
        "                y=y, sr=sr, hop_length=self.config.hop_length,\n",
        "                bins_per_octave=self.config.cqt_bins_per_octave,\n",
        "                n_bins=self.config.n_chroma * self.config.cqt_n_octaves\n",
        "            ))\n",
        "            S = np.abs(librosa.stft(y, n_fft=self.config.n_fft, hop_length=self.config.hop_length))\n",
        "\n",
        "            features.extend(self._extract_pitch(CQT))\n",
        "            features.extend(self._extract_timbre(S, sr))\n",
        "            features.extend(self._extract_spectral(S, sr))\n",
        "            features.extend(self._extract_signal(y, S))\n",
        "            return features\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def _extract_pitch(self, CQT: np.ndarray) -> List[float]:\n",
        "        chroma = librosa.feature.chroma_cqt(C=CQT, bins_per_octave=self.config.n_chroma, n_chroma=self.config.n_chroma)\n",
        "        features = np.empty(self.config.n_chroma * 2, dtype=np.float32)\n",
        "        features[0::2] = np.mean(chroma, axis=1)\n",
        "        features[1::2] = np.var(chroma, axis=1)\n",
        "        return features.tolist()\n",
        "\n",
        "    def _extract_timbre(self, S: np.ndarray, sr: int) -> List[float]:\n",
        "        mfcc = librosa.feature.mfcc(S=librosa.power_to_db(S), sr=sr, n_mfcc=self.config.n_mfcc, hop_length=self.config.hop_length)\n",
        "        features = np.empty(self.config.n_mfcc * 2, dtype=np.float32)\n",
        "        features[0::2] = np.mean(mfcc, axis=1)\n",
        "        features[1::2] = np.var(mfcc, axis=1)\n",
        "        return features.tolist()\n",
        "\n",
        "    def _extract_spectral(self, S: np.ndarray, sr: int) -> List[float]:\n",
        "        features = []\n",
        "        centroid = librosa.feature.spectral_centroid(S=S, sr=sr, hop_length=self.config.hop_length)\n",
        "        features.extend([float(np.mean(centroid)), float(np.var(centroid))])\n",
        "\n",
        "        # Dynamic loop to prevent IndexErrors\n",
        "        contrast = librosa.feature.spectral_contrast(S=S, sr=sr, hop_length=self.config.hop_length, n_bands=self.config.n_contrast_bands - 1)\n",
        "        means, vars = np.mean(contrast, axis=1), np.var(contrast, axis=1)\n",
        "\n",
        "        # Use actual return size to loop safely\n",
        "        for i in range(len(means)):\n",
        "            features.extend([float(means[i]), float(vars[i])])\n",
        "\n",
        "        # Pad with zeros if less than config (safety net)\n",
        "        expected_len = self.config.n_contrast_bands * 2\n",
        "        current_len = len(means) * 2\n",
        "        if current_len < expected_len:\n",
        "            features.extend([0.0] * (expected_len - current_len))\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _extract_signal(self, y: np.ndarray, S: np.ndarray) -> List[float]:\n",
        "        zcr = librosa.feature.zero_crossing_rate(y, hop_length=self.config.hop_length)\n",
        "        rms = librosa.feature.rms(S=S, hop_length=self.config.hop_length)\n",
        "        return [float(np.mean(zcr)), float(np.var(zcr)), float(np.mean(rms)), float(np.var(rms))]\n",
        "\n",
        "def get_headers(config: AudioConfig) -> List[str]:\n",
        "    # Added 'filename' to headers\n",
        "    cols = ['filename']\n",
        "    for i in range(config.n_chroma): cols.extend([f'chroma_mean_{i}', f'chroma_var_{i}'])\n",
        "    for i in range(config.n_mfcc): cols.extend([f'mfcc_mean_{i}', f'mfcc_var_{i}'])\n",
        "    cols.extend(['centroid_mean', 'centroid_var'])\n",
        "    for i in range(config.n_contrast_bands): cols.extend([f'contrast_mean_{i}', f'contrast_var_{i}'])\n",
        "    cols.extend(['zcr_mean', 'zcr_var', 'rms_mean', 'rms_var', 'label'])\n",
        "    return cols\n",
        "\n",
        "# 4. PROCESSOR (FOR SEGMENTATION)\n",
        "class AudioProcessor:\n",
        "    def __init__(self, audio_config):\n",
        "        self.audio_config = audio_config\n",
        "        self.extractor = FeatureExtractor(audio_config)\n",
        "\n",
        "    def process_single_file(self, file_info):\n",
        "        file_path, label, unique_filename = file_info\n",
        "        batch_features = [] # Will store multiple rows if file > 30s\n",
        "\n",
        "        try:\n",
        "            # 1. LOAD FULL FILE\n",
        "            y, sr = librosa.load(file_path, sr=self.audio_config.sample_rate)\n",
        "\n",
        "            # 2. TRIM SILENCE\n",
        "            y, _ = librosa.effects.trim(y, top_db=self.audio_config.trim_top_db)\n",
        "\n",
        "            # 3. SEGMENTATION LOOP\n",
        "            samples_per_chunk = int(self.audio_config.max_audio_duration * sr)\n",
        "            total_samples = len(y)\n",
        "\n",
        "            # Case A: Short file (Single Chunk)\n",
        "            if total_samples <= samples_per_chunk:\n",
        "                features = self.extractor.extract_features(y, sr)\n",
        "                if features:\n",
        "                    batch_features.append([unique_filename] + features + [label])\n",
        "\n",
        "            # Case B: Long file (Multi Chunk)\n",
        "            else:\n",
        "                num_chunks = math.ceil(total_samples / samples_per_chunk)\n",
        "                for i in range(num_chunks):\n",
        "                    start = i * samples_per_chunk\n",
        "                    end = start + samples_per_chunk\n",
        "                    y_chunk = y[start:end]\n",
        "\n",
        "                    if len(y_chunk) >= (self.audio_config.min_audio_duration * sr):\n",
        "                        features = self.extractor.extract_features(y_chunk, sr)\n",
        "                        if features:\n",
        "                            # Both chunks get SAME filename, allowing GroupKFold later\n",
        "                            batch_features.append([unique_filename] + features + [label])\n",
        "\n",
        "            return batch_features if len(batch_features) > 0 else None\n",
        "\n",
        "        except Exception as e:\n",
        "            return None\n",
        "\n",
        "# 5. MAIN PIPELINE\n",
        "def run_pipeline(dataset_path: str, output_csv: str = \"maqam_features.csv\"):\n",
        "    print(f\"MAQAM PIPELINE STARTED at: {dataset_path}\")\n",
        "    print(f\"Mode: Segmentation (Max Chunk: {AUDIO_CONFIG.max_audio_duration}s)\")\n",
        "    print(\"Fix Applied: 'filename' column added for Leakage Prevention.\")\n",
        "\n",
        "    # 1. Setup CSV\n",
        "    cols = get_headers(AUDIO_CONFIG)\n",
        "    pd.DataFrame(columns=cols).to_csv(output_csv, index=False)\n",
        "\n",
        "    # 2. Collect Files\n",
        "    parser = DatasetParser(dataset_path)\n",
        "    real_root = parser.find_dataset_root()\n",
        "\n",
        "    tasks = parser.collect_audio_files(real_root)\n",
        "\n",
        "    if len(tasks) == 0:\n",
        "        print(\"CRITICAL ERROR: NO AUDIO FILES FOUND.\")\n",
        "        return\n",
        "\n",
        "    print(f\"✓ Found {len(tasks)} raw audio files.\")\n",
        "\n",
        "    # 3. Process - STREAMING MODE\n",
        "    processor = AudioProcessor(AUDIO_CONFIG)\n",
        "    total_segments = 0\n",
        "    buffer = []\n",
        "\n",
        "    print(\"\\nStarting Segmented Extraction...\")\n",
        "\n",
        "    with ProcessPoolExecutor(max_workers=PROCESSING_CONFIG.max_workers) as executor:\n",
        "        future_to_file = {executor.submit(processor.process_single_file, t): t for t in tasks}\n",
        "\n",
        "        with tqdm(total=len(tasks), unit=\"files\") as pbar:\n",
        "            for future in as_completed(future_to_file):\n",
        "                try:\n",
        "                    result_batch = future.result()\n",
        "\n",
        "                    if result_batch:\n",
        "                        buffer.extend(result_batch)\n",
        "\n",
        "                        if len(buffer) >= 20:\n",
        "                            pd.DataFrame(buffer, columns=cols).to_csv(output_csv, mode='a', header=False, index=False)\n",
        "                            total_segments += len(buffer)\n",
        "                            buffer = []\n",
        "\n",
        "                except Exception as e:\n",
        "                    pass\n",
        "                pbar.update(1)\n",
        "\n",
        "    # Write remaining buffer\n",
        "    if buffer:\n",
        "        pd.DataFrame(buffer, columns=cols).to_csv(output_csv, mode='a', header=False, index=False)\n",
        "        total_segments += len(buffer)\n",
        "\n",
        "    print(f\"\\nPipeline Finished. Extracted {total_segments} segments from {len(tasks)} files.\")\n",
        "\n",
        "    try:\n",
        "        df_final = pd.read_csv(output_csv)\n",
        "        print(f\"✓ Final CSV has {len(df_final)} rows.\")\n",
        "        files.download(output_csv)\n",
        "    except:\n",
        "        print(\"Could not automatically download. Check the file browser on the left.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    gc.collect()\n",
        "    dataset_path = download_and_extract_figshare()\n",
        "    if dataset_path:\n",
        "        run_pipeline(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "import traceback\n",
        "from typing import Tuple, List, Optional\n",
        "from dataclasses import dataclass\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# CONFIGURATION\n",
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"Centralized configuration for the EDA pipeline.\"\"\"\n",
        "    # File paths\n",
        "    input_csv: str = \"maqam_features.csv\"\n",
        "    raw_audio_dir: str = \"dataset_root\"\n",
        "    output_csv: str = \"maqam_features_processed.csv\"\n",
        "    figure_dir: str = 'paper_figures'\n",
        "\n",
        "    # Analysis parameters\n",
        "    seed: int = 42\n",
        "    train_ratio: float = 0.8\n",
        "    tsne_perplexity: int = 30\n",
        "    tsne_n_iter: int = 1000\n",
        "\n",
        "    # Columns to ignore during numerical feature extraction\n",
        "    columns_to_exclude: Tuple[str, ...] = ('label', 'filename', 'Unnamed: 0')\n",
        "\n",
        "    # Visualization settings\n",
        "    style: str = \"whitegrid\"\n",
        "    context: str = \"paper\"\n",
        "    font_scale: float = 1.2\n",
        "    figure_dpi: int = 300\n",
        "    grid_alpha: float = 0.3\n",
        "\n",
        "    def __post_init__(self):\n",
        "        os.makedirs(self.figure_dir, exist_ok=True)\n",
        "        self._setup_visualization()\n",
        "\n",
        "    def _setup_visualization(self):\n",
        "        sns.set_theme(style=self.style, context=self.context, font_scale=self.font_scale)\n",
        "        plt.rcParams.update({\n",
        "            'figure.dpi': self.figure_dpi,\n",
        "            'savefig.bbox': 'tight',\n",
        "            'axes.grid': True,\n",
        "            'grid.alpha': self.grid_alpha,\n",
        "            'font.family': 'serif'\n",
        "        })\n",
        "        np.random.seed(self.seed)\n",
        "\n",
        "CFG = Config()\n",
        "\n",
        "# 1. DATA PROCESSING\n",
        "def load_and_clean_data(file_path: str) -> pd.DataFrame:\n",
        "    print(f\"{'='*70}\\nPhase 1: Data Loading\\n{'='*70}\")\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"File not found: {file_path}. Please run feature extraction first.\")\n",
        "\n",
        "    df = pd.read_csv(file_path)\n",
        "    df = df.dropna()\n",
        "\n",
        "    # Check for filename\n",
        "    if 'filename' not in df.columns:\n",
        "        print(\"Warning: 'filename' column missing. Ensure this is expected.\")\n",
        "\n",
        "    print(f\"✓ Dataset loaded: {len(df)} samples across {df['label'].nunique()} Maqam classes.\")\n",
        "    return df\n",
        "\n",
        "def split_data_stratified(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Performs a standard STRATIFIED split.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*70}\\nPhase 2: Stratified Data Splitting\\n{'='*70}\")\n",
        "\n",
        "    train_df, test_df = train_test_split(\n",
        "        df,\n",
        "        test_size=(1 - CFG.train_ratio),\n",
        "        stratify=df['label'],\n",
        "        random_state=CFG.seed\n",
        "    )\n",
        "\n",
        "    print(f\"Training set: {len(train_df)} samples\")\n",
        "    print(f\"Test set:     {len(test_df)} samples\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "def get_feature_columns(df: pd.DataFrame) -> List[str]:\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    return [col for col in numeric_cols if col not in CFG.columns_to_exclude]\n",
        "\n",
        "# 2. VISUALIZATION\n",
        "class EDAPlotter:\n",
        "    @staticmethod\n",
        "    def plot_class_balance(df: pd.DataFrame):\n",
        "        print(f\"Generating Figure 1: Full Dataset Distribution (N={len(df)})...\")\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        counts = df['label'].value_counts()\n",
        "        sns.barplot(x=counts.index, y=counts.values, palette='viridis')\n",
        "\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.xlabel(\"Maqam Class\")\n",
        "        plt.ylabel(\"Total Samples Count\")\n",
        "\n",
        "        plt.text(0.95, 0.95, f'Total Dataset N={len(df)}',\n",
        "                 transform=plt.gca().transAxes, ha='right', va='top',\n",
        "                 bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{CFG.figure_dir}/Fig1_Class_Distribution.png', dpi=CFG.figure_dpi)\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_melodic_fingerprint(train_df: pd.DataFrame):\n",
        "        print(\"Generating Figure 2: Melodic Fingerprint...\")\n",
        "        chroma_cols = [c for c in train_df.columns if 'chroma_mean' in c]\n",
        "        if not chroma_cols: return\n",
        "        chroma_cols.sort(key=lambda x: int(x.split('_')[-1]))\n",
        "\n",
        "        maqam_profiles = train_df[chroma_cols + ['label']].groupby('label').mean()\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        sns.heatmap(maqam_profiles, cmap='magma', linewidths=0.5, cbar_kws={'label': 'Intensity'})\n",
        "        plt.xlabel(\"Chroma Bin Index (Quarter Tones)\")\n",
        "        plt.ylabel(\"Maqam Label\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{CFG.figure_dir}/Fig2_Melodic_Fingerprint.png', dpi=CFG.figure_dpi)\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_dendrogram(train_df: pd.DataFrame):\n",
        "        print(\"Generating Figure 3: Hierarchical Dendrogram...\")\n",
        "        feature_cols = get_feature_columns(train_df)\n",
        "\n",
        "        # 1. Group by label\n",
        "        class_means = train_df.groupby('label')[feature_cols].mean()\n",
        "\n",
        "        # 2. Calculate Ward Linkage\n",
        "        Z = linkage(class_means, method='ward')\n",
        "\n",
        "        plt.figure(figsize=(12, 7))\n",
        "\n",
        "        # 3. Plot Dendrogram\n",
        "        dendro = dendrogram(\n",
        "            Z,\n",
        "            labels=class_means.index,\n",
        "            leaf_rotation=45,\n",
        "            leaf_font_size=12\n",
        "        )\n",
        "\n",
        "        plt.ylabel(\"Euclidean Distance\")\n",
        "        plt.xlabel(\"Maqam Families\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{CFG.figure_dir}/Fig3_Dendrogram.png', dpi=CFG.figure_dpi)\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_spectrograms():\n",
        "        print(\"Generating Figure 4: Spectrogram Comparison (All Classes)...\")\n",
        "\n",
        "        class_files = {}\n",
        "        if not os.path.exists(CFG.raw_audio_dir):\n",
        "            print(\"Skipping spectrograms: Raw audio directory not found.\")\n",
        "            return\n",
        "\n",
        "        for root, dirs, files in os.walk(CFG.raw_audio_dir):\n",
        "            for f in files:\n",
        "                if f.endswith('.wav'):\n",
        "                    label = os.path.basename(root)\n",
        "                    if label not in class_files:\n",
        "                        class_files[label] = os.path.join(root, f)\n",
        "\n",
        "        if not class_files:\n",
        "            print(\"Skipping: No audio files found.\")\n",
        "            return\n",
        "\n",
        "        labels = sorted(class_files.keys())\n",
        "        n_classes = len(labels)\n",
        "        n_cols = 3\n",
        "        n_rows = int(np.ceil(n_classes / n_cols))\n",
        "\n",
        "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 3.5*n_rows), sharex=True, sharey=True)\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for i, label in enumerate(labels):\n",
        "            path = class_files[label]\n",
        "            ax = axes[i]\n",
        "\n",
        "            try:\n",
        "                y, sr = librosa.load(path, duration=5)\n",
        "                S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "                S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "                # Plot Spectrogram\n",
        "                img = librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=sr, ax=ax, cmap='magma')\n",
        "\n",
        "                # Label overlay\n",
        "                ax.text(0.05, 0.9, label, transform=ax.transAxes,\n",
        "                        color='white', fontweight='bold', fontsize=10,\n",
        "                        bbox=dict(facecolor='black', alpha=0.5))\n",
        "\n",
        "                # Standardize Axis Labels\n",
        "                ax.set_xlabel(\"Time (s)\")\n",
        "                ax.set_ylabel(\"Frequency (Hz)\")\n",
        "\n",
        "                # Optimize labels for shared axes\n",
        "                ax.label_outer()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error plotting {label}: {e}\")\n",
        "\n",
        "        # Hide empty subplots\n",
        "        for j in range(i+1, len(axes)):\n",
        "            axes[j].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{CFG.figure_dir}/Fig4_Spectrograms.png', dpi=CFG.figure_dpi)\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_tsne_manifold(train_df: pd.DataFrame):\n",
        "        print(\"Generating Figure 5: t-SNE Manifold...\")\n",
        "        feature_cols = get_feature_columns(train_df)\n",
        "        if len(train_df) > 5000:\n",
        "            plot_df = train_df.sample(5000, random_state=CFG.seed)\n",
        "        else:\n",
        "            plot_df = train_df.copy()\n",
        "\n",
        "        X = plot_df[feature_cols].fillna(0)\n",
        "        X_scaled = StandardScaler().fit_transform(X)\n",
        "\n",
        "        tsne = TSNE(n_components=2, random_state=CFG.seed,\n",
        "                    perplexity=CFG.tsne_perplexity, n_iter=CFG.tsne_n_iter, n_jobs=-1)\n",
        "        X_embedded = tsne.fit_transform(X_scaled)\n",
        "\n",
        "        tsne_df = pd.DataFrame(X_embedded, columns=['Dim1', 'Dim2'])\n",
        "        tsne_df['Maqam'] = plot_df['label'].values\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.scatterplot(\n",
        "            data=tsne_df, x='Dim1', y='Dim2', hue='Maqam',\n",
        "            palette='bright', alpha=0.7, s=50\n",
        "        )\n",
        "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{CFG.figure_dir}/Fig5_tSNE_Manifold.png', dpi=CFG.figure_dpi)\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_correlation_matrix(train_df: pd.DataFrame):\n",
        "        print(\"Generating Figure 6: Feature Correlations...\")\n",
        "\n",
        "        subset_cols = []\n",
        "        for prefix in ['mfcc_mean', 'chroma_mean', 'contrast_mean']:\n",
        "            cols = [c for c in train_df.columns if prefix in c]\n",
        "            subset_cols.extend(cols[:3])\n",
        "\n",
        "        spec_features = ['zcr_mean', 'rms_mean']\n",
        "        subset_cols.extend([c for c in spec_features if c in train_df.columns])\n",
        "\n",
        "        if len(subset_cols) < 2: return\n",
        "\n",
        "        corr = train_df[subset_cols].corr()\n",
        "\n",
        "        plt.figure(figsize=(10, 10))\n",
        "\n",
        "        sns.heatmap(\n",
        "            corr,\n",
        "            cmap='coolwarm',\n",
        "            center=0,\n",
        "            annot=True,\n",
        "            fmt=\".2f\",\n",
        "            square=True,\n",
        "            cbar_kws={\"shrink\": 0.8},\n",
        "            annot_kws={\"size\": 10}\n",
        "        )\n",
        "\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.yticks(rotation=0)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{CFG.figure_dir}/Fig6_Correlation_Matrix.png', dpi=CFG.figure_dpi, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "# 3. PIPELINE RUNNER\n",
        "def run_eda_pipeline():\n",
        "    try:\n",
        "        print(\"=\" * 70)\n",
        "        print(\"MAQAM EDA PIPELINE\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # 1. Load Data\n",
        "        df = load_and_clean_data(CFG.input_csv)\n",
        "\n",
        "        # 2. PLOT FULL DISTRIBUTION (Before Split)\n",
        "        plotter = EDAPlotter()\n",
        "        plotter.plot_class_balance(df)\n",
        "\n",
        "        # 3. Split (Original Stratified Split)\n",
        "        train_df, test_df = split_data_stratified(df)\n",
        "\n",
        "        # 4. Save Splits\n",
        "        train_df.to_csv(\"train_split.csv\", index=False)\n",
        "        test_df.to_csv(\"test_split.csv\", index=False)\n",
        "        print(\"✓ Saved train_split.csv and test_split.csv\")\n",
        "\n",
        "        # 5. Plot the rest\n",
        "        print(f\"\\n{'='*70}\\nPhase 3: Generating Feature Visuals (Train Set Only)\\n{'='*70}\")\n",
        "        plotter.plot_melodic_fingerprint(train_df)\n",
        "        plotter.plot_dendrogram(train_df)\n",
        "        plotter.plot_spectrograms()\n",
        "        plotter.plot_tsne_manifold(train_df)\n",
        "        plotter.plot_correlation_matrix(train_df)\n",
        "\n",
        "        print(f\"\\nPipeline Finished. Figures saved in '{CFG.figure_dir}/'\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nERROR: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_eda_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxSji8uDw7nd",
        "outputId": "dea9a5e6-494a-4d9d-96b2-5582ffadfc88"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "MAQAM EDA PIPELINE\n",
            "======================================================================\n",
            "======================================================================\n",
            "Phase 1: Data Loading\n",
            "======================================================================\n",
            "✓ Dataset loaded: 924 samples across 8 Maqam classes.\n",
            "Generating Figure 1: Full Dataset Distribution (N=924)...\n",
            "\n",
            "======================================================================\n",
            "Phase 2: Stratified Data Splitting\n",
            "======================================================================\n",
            "Training set: 739 samples\n",
            "Test set:     185 samples\n",
            "✓ Saved train_split.csv and test_split.csv\n",
            "\n",
            "======================================================================\n",
            "Phase 3: Generating Feature Visuals (Train Set Only)\n",
            "======================================================================\n",
            "Generating Figure 2: Melodic Fingerprint...\n",
            "Generating Figure 3: Hierarchical Dendrogram...\n",
            "Generating Figure 4: Spectrogram Comparison (All Classes)...\n",
            "Generating Figure 5: t-SNE Manifold...\n",
            "Generating Figure 6: Feature Correlations...\n",
            "\n",
            "Pipeline Finished. Figures saved in 'paper_figures/'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import os\n",
        "import joblib\n",
        "import shap\n",
        "import gc   # Added for garbage collection\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import GridSearchCV, learning_curve, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, label_binarize\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             roc_curve, auc, confusion_matrix)\n",
        "\n",
        "# PLOTTING CONFIGURATION\n",
        "plt.rcParams.update({\n",
        "    'font.size': 12,\n",
        "    'font.family': 'sans-serif',\n",
        "    'axes.labelsize': 14, 'axes.titlesize': 16,\n",
        "    'legend.fontsize': 11, 'xtick.labelsize': 11, 'ytick.labelsize': 11,\n",
        "    'figure.dpi': 300, 'savefig.dpi': 300, 'axes.grid': True, 'grid.alpha': 0.3\n",
        "})\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# CONFIG\n",
        "class Config:\n",
        "    train_path = \"train_split.csv\"\n",
        "    test_path = \"test_split.csv\"\n",
        "    out_dir = \"paper_results\"\n",
        "    seed = 42\n",
        "    cv_folds = 10\n",
        "    n_jobs = 1\n",
        "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
        "\n",
        "    # Explainability settings\n",
        "    shap_background_samples = 10\n",
        "\n",
        "CFG = Config()\n",
        "Path(CFG.out_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1. DATA LOADING\n",
        "def load_data():\n",
        "    print(\"Loading data...\")\n",
        "    train = pd.read_csv(CFG.train_path)\n",
        "    test = pd.read_csv(CFG.test_path)\n",
        "\n",
        "    meta_cols = ['label', 'filename', 'filepath', 'track_id', 'recording_id']\n",
        "    X_train = train.drop(columns=meta_cols, errors='ignore')\n",
        "    y_train = train['label']\n",
        "    X_test = test.drop(columns=meta_cols, errors='ignore')\n",
        "    y_test = test['label']\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(y_train)\n",
        "    y_test = le.transform(y_test)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_s = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
        "    X_test_s = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
        "\n",
        "    return X_train_s, y_train, X_test_s, y_test, le\n",
        "\n",
        "# 2. MODEL TRAINING\n",
        "def train_models(X_train, y_train):\n",
        "    print(\"Training models...\")\n",
        "\n",
        "    models = {\n",
        "        'Logistic Regression': LogisticRegression(random_state=CFG.seed, max_iter=2000),\n",
        "        'KNN': KNeighborsClassifier(),\n",
        "        'Random Forest': RandomForestClassifier(random_state=CFG.seed),\n",
        "        'SVM': SVC(probability=True, random_state=CFG.seed, kernel='rbf', class_weight='balanced')\n",
        "    }\n",
        "\n",
        "    grids = {\n",
        "        'Logistic Regression': {'C': [0.1, 1, 10]},\n",
        "        'KNN': {'n_neighbors': [5, 9, 15]},\n",
        "        'Random Forest': {'n_estimators': [100, 200], 'max_depth': [10, 20]},\n",
        "        'SVM': {'C': [1, 10], 'gamma': ['scale', 0.01]}\n",
        "    }\n",
        "\n",
        "    best_models = {}\n",
        "    cv_scores = {}\n",
        "    best_params = {}\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=CFG.cv_folds, shuffle=True, random_state=CFG.seed)\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"  Optimizing {name}...\")\n",
        "        gs = GridSearchCV(model, grids[name], cv=cv, scoring='accuracy', n_jobs=CFG.n_jobs)\n",
        "        gs.fit(X_train, y_train)\n",
        "\n",
        "        best_models[name] = gs.best_estimator_\n",
        "        cv_scores[name] = gs.best_score_\n",
        "        best_params[name] = gs.best_params_\n",
        "\n",
        "    return best_models, cv_scores, best_params\n",
        "\n",
        "# 3. EVALUATION\n",
        "def evaluate(models, cv_scores, X_test, y_test):\n",
        "    \"\"\"Calculate aggregate metrics.\"\"\"\n",
        "    results = []\n",
        "    for name, model in models.items():\n",
        "        p = model.predict(X_test)\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'CV Accuracy': cv_scores[name],\n",
        "            'Test Accuracy': accuracy_score(y_test, p),\n",
        "            'Precision': precision_score(y_test, p, average='weighted', zero_division=0),\n",
        "            'Recall': recall_score(y_test, p, average='weighted', zero_division=0),\n",
        "            'F1 Score': f1_score(y_test, p, average='weighted', zero_division=0)\n",
        "        })\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# 4. VISUALIZATION\n",
        "def plot_metrics(df):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # 1. Filter OUT CV Accuracy\n",
        "    df_plot = df.drop(columns=['CV Accuracy'])\n",
        "\n",
        "    # 2. Rename 'Test Accuracy' to 'Accuracy'\n",
        "    df_plot = df_plot.rename(columns={'Test Accuracy': 'Accuracy'})\n",
        "\n",
        "    df_melt = df_plot.melt(id_vars=\"Model\", var_name=\"Metric\", value_name=\"Score\")\n",
        "\n",
        "    ax = sns.barplot(data=df_melt, x=\"Metric\", y=\"Score\", hue=\"Model\", palette=\"viridis\")\n",
        "\n",
        "    for c in ax.containers:\n",
        "        # Rotation 0 for horizontal numbers\n",
        "        ax.bar_label(c, fmt='%.2f', padding=3, fontsize=9, rotation=0)\n",
        "\n",
        "    plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
        "    plt.ylim(0, 1.25)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{CFG.out_dir}/Fig1_Metrics.png\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_combined_roc(models, X_test, y_test, le):\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    y_bin = label_binarize(y_test, classes=range(len(le.classes_)))\n",
        "\n",
        "    for (name, model), color in zip(models.items(), CFG.colors):\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            probs = model.predict_proba(X_test)\n",
        "            fpr, tpr, _ = roc_curve(y_bin.ravel(), probs.ravel())\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            plt.plot(fpr, tpr, label=f'{name} (AUC={roc_auc:.2f})', color=color, lw=2.5)\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=1.5)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{CFG.out_dir}/Fig2_ROC.png\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_learning_curves(models, X_train, y_train):\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, (name, model) in enumerate(models.items()):\n",
        "        ax = axes[i]\n",
        "        # 10 points for smoother curves\n",
        "        sizes, train_scores, test_scores = learning_curve(\n",
        "            model, X_train, y_train, cv=CFG.cv_folds, n_jobs=CFG.n_jobs,\n",
        "            train_sizes=np.linspace(0.1, 1.0, 10), scoring='accuracy'\n",
        "        )\n",
        "\n",
        "        train_mean = np.mean(train_scores, axis=1)\n",
        "        train_std = np.std(train_scores, axis=1)\n",
        "        test_mean = np.mean(test_scores, axis=1)\n",
        "        test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "        ax.plot(sizes, train_mean, 'o-', color=CFG.colors[0], label='Train')\n",
        "        ax.plot(sizes, test_mean, 's-', color=CFG.colors[1], label='CV (Validation)')\n",
        "\n",
        "        ax.fill_between(sizes, test_mean - test_std, test_mean + test_std,\n",
        "                        alpha=0.15, color=CFG.colors[1])\n",
        "\n",
        "        ax.set_title(name, fontweight='bold')\n",
        "        ax.set_ylim(0.4, 1.05)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        if i==0: ax.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{CFG.out_dir}/Fig3_LearningCurves.png\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_loss_curves(models, X_train, y_train):\n",
        "    print(\"Generating Loss Curves...\")\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, (name, model) in enumerate(models.items()):\n",
        "        ax = axes[i]\n",
        "        # 10 points for smoother curves\n",
        "        sizes, train_scores, test_scores = learning_curve(\n",
        "            model, X_train, y_train, cv=CFG.cv_folds, n_jobs=CFG.n_jobs,\n",
        "            train_sizes=np.linspace(0.1, 1.0, 10), scoring='neg_log_loss'\n",
        "        )\n",
        "\n",
        "        train_loss = -np.mean(train_scores, axis=1)\n",
        "        test_loss = -np.mean(test_scores, axis=1)\n",
        "\n",
        "        ax.plot(sizes, train_loss, 'o-', color='#d62728', label='Train Loss')\n",
        "        ax.plot(sizes, test_loss, 's-', color='#2ca02c', label='Validation Loss')\n",
        "\n",
        "        ax.set_title(name, fontweight='bold')\n",
        "        ax.set_xlabel(\"Training Examples\")\n",
        "        ax.set_ylabel(\"Log Loss\")\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        if i==0: ax.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{CFG.out_dir}/Fig4_LossCurves.png\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrices(models, X_test, y_test, le):\n",
        "    \"\"\"Generates a 2x2 grid of confusion matrices.\"\"\"\n",
        "    print(\"Generating Confusion Matrices...\")\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, (name, model) in enumerate(models.items()):\n",
        "        ax = axes[i]\n",
        "        y_pred = model.predict(X_test)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        # Plot heatmap\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "                    xticklabels=le.classes_, yticklabels=le.classes_, cbar=False)\n",
        "\n",
        "        ax.set_title(name, fontweight='bold')\n",
        "        ax.set_xlabel('Predicted Label')\n",
        "        ax.set_ylabel('True Label')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{CFG.out_dir}/Fig6_ConfusionMatrices.png\")\n",
        "    plt.close()\n",
        "\n",
        "# 5. EXPLAINABILITY (SHAP)\n",
        "def aggregate_shap_data(shap_values, X_df):\n",
        "    df_shap = pd.DataFrame(shap_values, columns=X_df.columns)\n",
        "    col_to_group = {}\n",
        "    for col in X_df.columns:\n",
        "        parts = col.rsplit('_', 1)\n",
        "        if len(parts) > 1 and parts[1].isdigit():\n",
        "            col_to_group[col] = parts[0]\n",
        "        else:\n",
        "            col_to_group[col] = col\n",
        "\n",
        "    df_shap_grouped = df_shap.groupby(col_to_group, axis=1).sum()\n",
        "    df_X_grouped = X_df.groupby(col_to_group, axis=1).mean()\n",
        "    return df_shap_grouped.values, df_X_grouped\n",
        "\n",
        "def explain_models(models, X_train, X_test):\n",
        "    \"\"\"\n",
        "    2x2 SHAP Plot on FULL Test Set\n",
        "    \"\"\"\n",
        "    print(f\"\\nGenerating SHAP Explanations on FULL Test Set ({len(X_test)} samples)...\")\n",
        "\n",
        "    background_summary = shap.kmeans(X_train, CFG.shap_background_samples)\n",
        "\n",
        "    # 2x2 Grid Layout\n",
        "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 14))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, (name, model) in enumerate(models.items()):\n",
        "        print(f\"  Calculating SHAP for {name}...\")\n",
        "        plt.sca(axes[i])\n",
        "\n",
        "        try:\n",
        "            shap_values_raw = None\n",
        "\n",
        "            if \"Random Forest\" in name:\n",
        "                explainer = shap.TreeExplainer(model)\n",
        "                shap_values_raw = explainer.shap_values(X_test)\n",
        "\n",
        "            elif \"Logistic Regression\" in name:\n",
        "                explainer = shap.LinearExplainer(model, X_train)\n",
        "                shap_values_raw = explainer.shap_values(X_test)\n",
        "\n",
        "            else:\n",
        "                f = model.predict_proba if hasattr(model, 'predict_proba') else model.predict\n",
        "                explainer = shap.KernelExplainer(f, background_summary)\n",
        "                shap_values_raw = explainer.shap_values(X_test, silent=True)\n",
        "\n",
        "            if isinstance(shap_values_raw, list):\n",
        "                vals_to_plot = shap_values_raw[1]\n",
        "            elif hasattr(shap_values_raw, \"values\") and len(shap_values_raw.values.shape) == 3:\n",
        "                vals_to_plot = shap_values_raw.values[:, :, 1]\n",
        "            elif len(np.array(shap_values_raw).shape) == 3:\n",
        "                vals_to_plot = np.array(shap_values_raw)[:, :, 1]\n",
        "            else:\n",
        "                vals_to_plot = shap_values_raw\n",
        "\n",
        "            grouped_shap, grouped_X = aggregate_shap_data(vals_to_plot, X_test)\n",
        "\n",
        "            shap.summary_plot(\n",
        "                grouped_shap,\n",
        "                grouped_X,\n",
        "                feature_names=grouped_X.columns,\n",
        "                show=False,\n",
        "                plot_type=\"dot\",\n",
        "                max_display=20,\n",
        "                color_bar=False # REMOVED LEGEND\n",
        "            )\n",
        "\n",
        "            axes[i].set_title(f\"{name}\", fontsize=18, fontweight='bold', pad=10)\n",
        "            axes[i].tick_params(axis='y', labelsize=12)\n",
        "            axes[i].set_xlabel(\"SHAP value\", fontsize=12)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Error explaining {name}: {e}\")\n",
        "            axes[i].text(0.5, 0.5, f\"Error: {str(e)}\", ha='center')\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "    plt.subplots_adjust(wspace=0.4, hspace=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{CFG.out_dir}/Fig5_SHAP_Combined.png\", bbox_inches='tight', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "# MAIN\n",
        "if __name__ == \"__main__\":\n",
        "    X_train, y_train, X_test, y_test, le = load_data()\n",
        "\n",
        "    models, cv_scores, best_params = train_models(X_train, y_train)\n",
        "\n",
        "    print(\"\\nBest Hyperparameters found:\")\n",
        "    param_df = pd.Series(best_params, name='Best_Params').to_frame()\n",
        "    print(param_df)\n",
        "    param_df.to_csv(f\"{CFG.out_dir}/hyperparams.csv\")\n",
        "\n",
        "    metrics = evaluate(models, cv_scores, X_test, y_test)\n",
        "    print(\"\\nResults:\\n\", metrics)\n",
        "    metrics.to_csv(f\"{CFG.out_dir}/metrics.csv\", index=False)\n",
        "\n",
        "    print(\"\\nGenerating Figures...\")\n",
        "    plot_metrics(metrics)\n",
        "    plot_combined_roc(models, X_test, y_test, le)\n",
        "    plot_learning_curves(models, X_train, y_train)\n",
        "    plot_loss_curves(models, X_train, y_train)\n",
        "    plot_confusion_matrices(models, X_test, y_test, le) # New function added here\n",
        "\n",
        "    explain_models(models, X_train, X_test)\n",
        "\n",
        "    print(f\"Done. Results saved to {CFG.out_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPOVOBpegFL-",
        "outputId": "fb51e87a-06c5-43fc-c000-1552b8330a31"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Training models...\n",
            "  Optimizing Logistic Regression...\n",
            "  Optimizing KNN...\n",
            "  Optimizing Random Forest...\n",
            "  Optimizing SVM...\n",
            "\n",
            "Best Hyperparameters found:\n",
            "                                                Best_Params\n",
            "Logistic Regression                                {'C': 1}\n",
            "KNN                                      {'n_neighbors': 5}\n",
            "Random Forest        {'max_depth': 20, 'n_estimators': 200}\n",
            "SVM                             {'C': 10, 'gamma': 'scale'}\n",
            "\n",
            "Results:\n",
            "                  Model  CV Accuracy  Test Accuracy  Precision    Recall  \\\n",
            "0  Logistic Regression     0.887745       0.875676   0.875408  0.875676   \n",
            "1                  KNN     0.925565       0.908108   0.922074  0.908108   \n",
            "2        Random Forest     0.922936       0.918919   0.923920  0.918919   \n",
            "3                  SVM     0.963495       0.956757   0.957808  0.956757   \n",
            "\n",
            "   F1 Score  \n",
            "0  0.875139  \n",
            "1  0.910247  \n",
            "2  0.918411  \n",
            "3  0.957070  \n",
            "\n",
            "Generating Figures...\n",
            "Generating Loss Curves...\n",
            "Generating Confusion Matrices...\n",
            "\n",
            "Generating SHAP Explanations on FULL Test Set (185 samples)...\n",
            "  Calculating SHAP for Logistic Regression...\n",
            "  Calculating SHAP for KNN...\n",
            "  Calculating SHAP for Random Forest...\n",
            "  Calculating SHAP for SVM...\n",
            "Done. Results saved to paper_results\n"
          ]
        }
      ]
    }
  ]
}
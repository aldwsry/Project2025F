{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ad31f3fa5064423a44081a99a2d7564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_504bdd9a351a4b1b9653b5ee1b107b00",
              "IPY_MODEL_a75c3a96f6854816866409e3a5e7d3fc",
              "IPY_MODEL_9f22d589344f46acbc2703e5fcaf04fa"
            ],
            "layout": "IPY_MODEL_e2603d041d044a1ba4e308461e35d45a"
          }
        },
        "504bdd9a351a4b1b9653b5ee1b107b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdd8d4e5160740819420779fcd57f2d2",
            "placeholder": "​",
            "style": "IPY_MODEL_ec6ce10b68d84df4b384eb6c67dd736b",
            "value": "Downloading: 100%"
          }
        },
        "a75c3a96f6854816866409e3a5e7d3fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82bb33fda27e489d829edad4bf812069",
            "max": 3585820308,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1f33c7788c1494a87b67ff3d844422b",
            "value": 3585820308
          }
        },
        "9f22d589344f46acbc2703e5fcaf04fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46a27b0e569d4da48c458d468c71ddbc",
            "placeholder": "​",
            "style": "IPY_MODEL_6117b92cb7c541dcaaafe9df9c129b97",
            "value": " 3.34G/3.34G [01:51&lt;00:00, 34.9MiB/s]"
          }
        },
        "e2603d041d044a1ba4e308461e35d45a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdd8d4e5160740819420779fcd57f2d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec6ce10b68d84df4b384eb6c67dd736b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82bb33fda27e489d829edad4bf812069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1f33c7788c1494a87b67ff3d844422b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46a27b0e569d4da48c458d468c71ddbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6117b92cb7c541dcaaafe9df9c129b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "283ec1f086a94f6c8068e8ce5ec78af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b630f4fb4ea4942a1bf2f9bda94c8ea",
              "IPY_MODEL_e4ed487e937b44eb8eb187a345ce5fe3",
              "IPY_MODEL_d4c6cf3bacdc4c2497d42c99a0f53156"
            ],
            "layout": "IPY_MODEL_c8801b2618a34d3894a54f02dd294196"
          }
        },
        "1b630f4fb4ea4942a1bf2f9bda94c8ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d739173956724ec5ad950c17d196264e",
            "placeholder": "​",
            "style": "IPY_MODEL_ac7acb48acf1405e81a462f3c2a3b26a",
            "value": "100%"
          }
        },
        "e4ed487e937b44eb8eb187a345ce5fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98e55a7466734a4e95915740ea3902ff",
            "max": 478,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c63e9073e38e4c4186e85361ed61a94e",
            "value": 478
          }
        },
        "d4c6cf3bacdc4c2497d42c99a0f53156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4ef2e9a6dbb4b6da6d55c4626e7485b",
            "placeholder": "​",
            "style": "IPY_MODEL_489ad7e29f364b8a93eb623ce86e309d",
            "value": " 478/478 [03:49&lt;00:00,  2.59files/s]"
          }
        },
        "c8801b2618a34d3894a54f02dd294196": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d739173956724ec5ad950c17d196264e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac7acb48acf1405e81a462f3c2a3b26a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98e55a7466734a4e95915740ea3902ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c63e9073e38e4c4186e85361ed61a94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4ef2e9a6dbb4b6da6d55c4626e7485b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "489ad7e29f364b8a93eb623ce86e309d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307,
          "referenced_widgets": [
            "5ad31f3fa5064423a44081a99a2d7564",
            "504bdd9a351a4b1b9653b5ee1b107b00",
            "a75c3a96f6854816866409e3a5e7d3fc",
            "9f22d589344f46acbc2703e5fcaf04fa",
            "e2603d041d044a1ba4e308461e35d45a",
            "fdd8d4e5160740819420779fcd57f2d2",
            "ec6ce10b68d84df4b384eb6c67dd736b",
            "82bb33fda27e489d829edad4bf812069",
            "d1f33c7788c1494a87b67ff3d844422b",
            "46a27b0e569d4da48c458d468c71ddbc",
            "6117b92cb7c541dcaaafe9df9c129b97",
            "283ec1f086a94f6c8068e8ce5ec78af5",
            "1b630f4fb4ea4942a1bf2f9bda94c8ea",
            "e4ed487e937b44eb8eb187a345ce5fe3",
            "d4c6cf3bacdc4c2497d42c99a0f53156",
            "c8801b2618a34d3894a54f02dd294196",
            "d739173956724ec5ad950c17d196264e",
            "ac7acb48acf1405e81a462f3c2a3b26a",
            "98e55a7466734a4e95915740ea3902ff",
            "c63e9073e38e4c4186e85361ed61a94e",
            "b4ef2e9a6dbb4b6da6d55c4626e7485b",
            "489ad7e29f364b8a93eb623ce86e309d"
          ]
        },
        "id": "y0mQTAe3sQLB",
        "outputId": "f4dce4ea-dd3d-4b47-d17d-54624956190d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset from Figshare (File ID: 26372272)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/3.34G [00:00<?, ?iB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ad31f3fa5064423a44081a99a2d7564"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset...\n",
            "✓ Download and extraction complete.\n",
            "MAQAM PIPELINE STARTED at: dataset_root\n",
            "Mode: Segmentation (Max Chunk: 30.0s)\n",
            "Searching recursively for class folders...\n",
            "Scanning classes: ['Nahawand', 'Bayat', 'Kurd', 'Seka', 'Ajam', 'Hijaz', 'Rast', 'Saba']\n",
            "✓ Found 478 raw audio files.\n",
            "\n",
            "Starting Segmented Extraction...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/478 [00:00<?, ?files/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "283ec1f086a94f6c8068e8ce5ec78af5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pipeline Finished. Extracted 924 segments from 478 files.\n",
            "✓ Final CSV has 924 rows.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3de91ef4-fa56-4240-948d-1ab273d75db8\", \"maqam_features_segmented.csv\", 1917419)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import zipfile\n",
        "import requests\n",
        "import math\n",
        "from tqdm.auto import tqdm\n",
        "from google.colab import files\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, List, Tuple, Any\n",
        "import gc\n",
        "\n",
        "# CONFIGURATION\n",
        "@dataclass\n",
        "class AudioConfig:\n",
        "    sample_rate: int = 22050\n",
        "    n_chroma: int = 24          # 24 bins for quarter tones\n",
        "    n_mfcc: int = 20            # Standard for voice/timbre\n",
        "    n_contrast_bands: int = 7   # Spectral contrast\n",
        "    min_audio_duration: float = 2.0  # Increased min duration to avoid tiny chunks\n",
        "    max_audio_duration: float = 30.0 # This is now the CHUNK size\n",
        "    trim_top_db: int = 20\n",
        "    cqt_bins_per_octave: int = 24\n",
        "    cqt_n_octaves: int = 7\n",
        "    hop_length: int = 1024\n",
        "    n_fft: int = 2048\n",
        "    min_valid_length: float = 0.5\n",
        "\n",
        "@dataclass\n",
        "class ProcessingConfig:\n",
        "    max_workers: int = 2 # Set to 2 for Colab stability\n",
        "\n",
        "AUDIO_CONFIG = AudioConfig()\n",
        "PROCESSING_CONFIG = ProcessingConfig()\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 1. DATASET HELPER (DOWNLOADER)\n",
        "def download_and_extract_figshare(target_dir=\"dataset_root\"):\n",
        "    \"\"\"Downloads the specific Maqam478 dataset from Figshare.\"\"\"\n",
        "    url = \"https://figshare.com/ndownloader/files/26372272\"\n",
        "    zip_path = \"maqam_dataset.zip\"\n",
        "\n",
        "    if not os.path.exists(target_dir):\n",
        "        os.makedirs(target_dir)\n",
        "\n",
        "    print(f\"Downloading dataset from Figshare (File ID: 26372272)...\")\n",
        "    try:\n",
        "        response = requests.get(url, stream=True)\n",
        "        total_size = int(response.headers.get('content-length', 0))\n",
        "        block_size = 1024\n",
        "\n",
        "        with open(zip_path, 'wb') as file, tqdm(\n",
        "            desc=\"Downloading\",\n",
        "            total=total_size,\n",
        "            unit='iB',\n",
        "            unit_scale=True,\n",
        "            unit_divisor=1024,\n",
        "        ) as bar:\n",
        "            for data in response.iter_content(block_size):\n",
        "                size = file.write(data)\n",
        "                bar.update(size)\n",
        "\n",
        "        print(\"Extracting dataset...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(target_dir)\n",
        "\n",
        "        os.remove(zip_path)\n",
        "        print(\"✓ Download and extraction complete.\")\n",
        "        return target_dir\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading dataset: {e}\")\n",
        "        return None\n",
        "\n",
        "# 2. DATASET PARSER\n",
        "class DatasetParser:\n",
        "    def __init__(self, root_path: str):\n",
        "        self.root_path = root_path\n",
        "\n",
        "    def find_dataset_root(self) -> str:\n",
        "        if not os.path.exists(self.root_path):\n",
        "            raise FileNotFoundError(f\"Path '{self.root_path}' not found.\")\n",
        "\n",
        "        candidate_folders = ['Bayati', 'Rast', 'Sikah', 'Ajam', 'Nahawand', 'Saba', 'Hijaz', 'Kurd']\n",
        "\n",
        "        print(\"Searching recursively for class folders...\")\n",
        "        for root, dirs, files in os.walk(self.root_path):\n",
        "            matches = [d for d in dirs if d in candidate_folders]\n",
        "            if len(matches) >= 3:\n",
        "                return root\n",
        "\n",
        "        for root, dirs, files in os.walk(self.root_path):\n",
        "            if any(f.lower().endswith(('.wav', '.mp3')) for f in files):\n",
        "                return os.path.dirname(root)\n",
        "\n",
        "        return self.root_path\n",
        "\n",
        "    def collect_audio_files(self, dataset_root: str) -> List[Tuple[str, str, str]]:\n",
        "        file_tasks = []\n",
        "        valid_extensions = ('.wav', '.mp3', '.flac', '.ogg', '.m4a')\n",
        "\n",
        "        try:\n",
        "            items = [d for d in os.listdir(dataset_root) if os.path.isdir(os.path.join(dataset_root, d))]\n",
        "        except:\n",
        "            return []\n",
        "\n",
        "        print(f\"Scanning classes: {items}\")\n",
        "        for label in items:\n",
        "            label_dir = os.path.join(dataset_root, label)\n",
        "            for f in os.listdir(label_dir):\n",
        "                if f.lower().endswith(valid_extensions):\n",
        "                    file_path = os.path.join(label_dir, f)\n",
        "                    unique_id = f\"{label}/{f}\"\n",
        "                    file_tasks.append((file_path, label, unique_id))\n",
        "        return file_tasks\n",
        "\n",
        "# 3. FEATURE EXTRACTOR\n",
        "class FeatureExtractor:\n",
        "    def __init__(self, config: AudioConfig):\n",
        "        self.config = config\n",
        "\n",
        "    def extract_features(self, y: np.ndarray, sr: int) -> Optional[List[float]]:\n",
        "        try:\n",
        "            features = []\n",
        "            # Safety check for tiny chunks\n",
        "            if len(y) < sr * self.config.min_valid_length: return None\n",
        "\n",
        "            CQT = np.abs(librosa.cqt(\n",
        "                y=y, sr=sr, hop_length=self.config.hop_length,\n",
        "                bins_per_octave=self.config.cqt_bins_per_octave,\n",
        "                n_bins=self.config.n_chroma * self.config.cqt_n_octaves\n",
        "            ))\n",
        "            S = np.abs(librosa.stft(y, n_fft=self.config.n_fft, hop_length=self.config.hop_length))\n",
        "\n",
        "            features.extend(self._extract_pitch(CQT))\n",
        "            features.extend(self._extract_timbre(S, sr))\n",
        "            features.extend(self._extract_spectral(S, sr))\n",
        "            features.extend(self._extract_signal(y, S))\n",
        "            return features\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    def _extract_pitch(self, CQT: np.ndarray) -> List[float]:\n",
        "        chroma = librosa.feature.chroma_cqt(C=CQT, bins_per_octave=self.config.n_chroma, n_chroma=self.config.n_chroma)\n",
        "        features = np.empty(self.config.n_chroma * 2, dtype=np.float32)\n",
        "        features[0::2] = np.mean(chroma, axis=1)\n",
        "        features[1::2] = np.var(chroma, axis=1)\n",
        "        return features.tolist()\n",
        "\n",
        "    def _extract_timbre(self, S: np.ndarray, sr: int) -> List[float]:\n",
        "        mfcc = librosa.feature.mfcc(S=librosa.power_to_db(S), sr=sr, n_mfcc=self.config.n_mfcc, hop_length=self.config.hop_length)\n",
        "        features = np.empty(self.config.n_mfcc * 2, dtype=np.float32)\n",
        "        features[0::2] = np.mean(mfcc, axis=1)\n",
        "        features[1::2] = np.var(mfcc, axis=1)\n",
        "        return features.tolist()\n",
        "\n",
        "    def _extract_spectral(self, S: np.ndarray, sr: int) -> List[float]:\n",
        "        features = []\n",
        "        centroid = librosa.feature.spectral_centroid(S=S, sr=sr, hop_length=self.config.hop_length)\n",
        "        features.extend([float(np.mean(centroid)), float(np.var(centroid))])\n",
        "        contrast = librosa.feature.spectral_contrast(S=S, sr=sr, hop_length=self.config.hop_length, n_bands=self.config.n_contrast_bands - 1)\n",
        "        means, vars = np.mean(contrast, axis=1), np.var(contrast, axis=1)\n",
        "        for i in range(self.config.n_contrast_bands):\n",
        "            if i < len(means): features.extend([float(means[i]), float(vars[i])])\n",
        "            else: features.extend([0.0, 0.0])\n",
        "        return features\n",
        "\n",
        "    def _extract_signal(self, y: np.ndarray, S: np.ndarray) -> List[float]:\n",
        "        zcr = librosa.feature.zero_crossing_rate(y, hop_length=self.config.hop_length)\n",
        "        rms = librosa.feature.rms(S=S, hop_length=self.config.hop_length)\n",
        "        return [float(np.mean(zcr)), float(np.var(zcr)), float(np.mean(rms)), float(np.var(rms))]\n",
        "\n",
        "def get_headers(config: AudioConfig) -> List[str]:\n",
        "    cols = []\n",
        "    for i in range(config.n_chroma): cols.extend([f'chroma_mean_{i}', f'chroma_var_{i}'])\n",
        "    for i in range(config.n_mfcc): cols.extend([f'mfcc_mean_{i}', f'mfcc_var_{i}'])\n",
        "    cols.extend(['centroid_mean', 'centroid_var'])\n",
        "    for i in range(config.n_contrast_bands): cols.extend([f'contrast_mean_{i}', f'contrast_var_{i}'])\n",
        "    cols.extend(['zcr_mean', 'zcr_var', 'rms_mean', 'rms_var', 'label'])\n",
        "    return cols\n",
        "\n",
        "# 4. PROCESSOR (UPDATED FOR SEGMENTATION)\n",
        "class AudioProcessor:\n",
        "    def __init__(self, audio_config):\n",
        "        self.audio_config = audio_config\n",
        "        self.extractor = FeatureExtractor(audio_config)\n",
        "\n",
        "    def process_single_file(self, file_info):\n",
        "        file_path, label, unique_filename = file_info\n",
        "        batch_features = [] # Will store multiple rows if file > 30s\n",
        "\n",
        "        try:\n",
        "            # 1. LOAD FULL FILE (No Duration Limit Here)\n",
        "            y, sr = librosa.load(file_path, sr=self.audio_config.sample_rate)\n",
        "\n",
        "            # 2. TRIM SILENCE\n",
        "            y, _ = librosa.effects.trim(y, top_db=self.audio_config.trim_top_db)\n",
        "\n",
        "            # 3. SEGMENTATION LOOP\n",
        "            # Calculate how many samples in 30 seconds\n",
        "            samples_per_chunk = int(self.audio_config.max_audio_duration * sr)\n",
        "            total_samples = len(y)\n",
        "\n",
        "            # If shorter than chunk size, just process the whole thing (e.g. 20s file)\n",
        "            if total_samples <= samples_per_chunk:\n",
        "                features = self.extractor.extract_features(y, sr)\n",
        "                if features:\n",
        "                    batch_features.append(features + [label])\n",
        "\n",
        "            # If longer, slice it up (e.g. 70s file -> 30s, 30s, 10s)\n",
        "            else:\n",
        "                num_chunks = math.ceil(total_samples / samples_per_chunk)\n",
        "\n",
        "                for i in range(num_chunks):\n",
        "                    start = i * samples_per_chunk\n",
        "                    end = start + samples_per_chunk\n",
        "\n",
        "                    # Get the chunk\n",
        "                    y_chunk = y[start:end]\n",
        "\n",
        "                    # Only process if this specific chunk meets min duration\n",
        "                    if len(y_chunk) >= (self.audio_config.min_audio_duration * sr):\n",
        "                        features = self.extractor.extract_features(y_chunk, sr)\n",
        "                        if features:\n",
        "                            batch_features.append(features + [label])\n",
        "\n",
        "            return batch_features if len(batch_features) > 0 else None\n",
        "\n",
        "        except Exception as e:\n",
        "            # print(f\"Error processing {file_path}: {e}\") # Optional debugging\n",
        "            return None\n",
        "\n",
        "# 5. MAIN PIPELINE\n",
        "def run_pipeline(dataset_path: str, output_csv: str = \"maqam_features_segmented.csv\"):\n",
        "    print(f\"MAQAM PIPELINE STARTED at: {dataset_path}\")\n",
        "    print(f\"Mode: Segmentation (Max Chunk: {AUDIO_CONFIG.max_audio_duration}s)\")\n",
        "\n",
        "    # 1. Setup CSV\n",
        "    cols = get_headers(AUDIO_CONFIG)\n",
        "    pd.DataFrame(columns=cols).to_csv(output_csv, index=False)\n",
        "\n",
        "    # 2. Collect Files\n",
        "    parser = DatasetParser(dataset_path)\n",
        "    real_root = parser.find_dataset_root()\n",
        "\n",
        "    tasks = parser.collect_audio_files(real_root)\n",
        "\n",
        "    if len(tasks) == 0:\n",
        "        print(\"CRITICAL ERROR: NO AUDIO FILES FOUND.\")\n",
        "        return\n",
        "\n",
        "    print(f\"✓ Found {len(tasks)} raw audio files.\")\n",
        "\n",
        "    # 3. Process - STREAMING MODE\n",
        "    processor = AudioProcessor(AUDIO_CONFIG)\n",
        "    total_segments = 0\n",
        "    buffer = []\n",
        "\n",
        "    print(\"\\nStarting Segmented Extraction...\")\n",
        "\n",
        "    with ProcessPoolExecutor(max_workers=PROCESSING_CONFIG.max_workers) as executor:\n",
        "        future_to_file = {executor.submit(processor.process_single_file, t): t for t in tasks}\n",
        "\n",
        "        with tqdm(total=len(tasks), unit=\"files\") as pbar:\n",
        "            for future in as_completed(future_to_file):\n",
        "                try:\n",
        "                    result_batch = future.result() # This is now a LIST of rows\n",
        "\n",
        "                    if result_batch:\n",
        "                        # Extend buffer with ALL segments found in this file\n",
        "                        buffer.extend(result_batch)\n",
        "\n",
        "                        # Write buffer to disk periodically\n",
        "                        if len(buffer) >= 20:\n",
        "                            pd.DataFrame(buffer, columns=cols).to_csv(output_csv, mode='a', header=False, index=False)\n",
        "                            total_segments += len(buffer)\n",
        "                            buffer = []\n",
        "\n",
        "                except Exception as e:\n",
        "                    pass\n",
        "                pbar.update(1)\n",
        "\n",
        "    # Write remaining buffer\n",
        "    if buffer:\n",
        "        pd.DataFrame(buffer, columns=cols).to_csv(output_csv, mode='a', header=False, index=False)\n",
        "        total_segments += len(buffer)\n",
        "\n",
        "    print(f\"\\nPipeline Finished. Extracted {total_segments} segments from {len(tasks)} files.\")\n",
        "\n",
        "    try:\n",
        "        df_final = pd.read_csv(output_csv)\n",
        "        print(f\"✓ Final CSV has {len(df_final)} rows.\")\n",
        "        files.download(output_csv)\n",
        "    except:\n",
        "        print(\"Could not automatically download. Check the file browser on the left.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    gc.collect()\n",
        "    dataset_path = download_and_extract_figshare()\n",
        "    if dataset_path:\n",
        "        run_pipeline(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "import traceback\n",
        "from typing import Tuple, List, Optional\n",
        "from dataclasses import dataclass\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# CONFIGURATION\n",
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"Centralized configuration for the EDA pipeline.\"\"\"\n",
        "    # File paths\n",
        "    input_csv: str = \"maqam_features_segmented.csv\"\n",
        "    output_csv: str = \"maqam_features_processed.csv\"\n",
        "    figure_dir: str = 'paper_figures'\n",
        "\n",
        "    # Analysis parameters\n",
        "    seed: int = 42\n",
        "    train_ratio: float = 0.8\n",
        "    tsne_perplexity: int = 30\n",
        "    tsne_n_iter: int = 1000\n",
        "    feature_prefixes: Tuple[str, ...] = ('mfcc_mean', 'chroma_mean', 'contrast_mean')\n",
        "    columns_to_exclude: Tuple[str, ...] = ('label', 'filename', 'Unnamed: 0')\n",
        "\n",
        "    # Visualization settings\n",
        "    style: str = \"whitegrid\"\n",
        "    context: str = \"paper\"\n",
        "    font_scale: float = 1.2\n",
        "    figure_dpi: int = 150\n",
        "    grid_alpha: float = 0.3\n",
        "\n",
        "    def __post_init__(self):\n",
        "        os.makedirs(self.figure_dir, exist_ok=True)\n",
        "        self._setup_visualization()\n",
        "\n",
        "    def _setup_visualization(self):\n",
        "        sns.set_theme(style=self.style, context=self.context, font_scale=self.font_scale)\n",
        "        plt.rcParams.update({\n",
        "            'figure.dpi': self.figure_dpi,\n",
        "            'savefig.bbox': 'tight',\n",
        "            'axes.grid': True,\n",
        "            'grid.alpha': self.grid_alpha\n",
        "        })\n",
        "        np.random.seed(self.seed)\n",
        "\n",
        "CFG = Config()\n",
        "\n",
        "# 1. DATA PROCESSING\n",
        "def load_and_clean_data(file_path: str) -> pd.DataFrame:\n",
        "    \"\"\"Loads data and performs basic cleaning.\"\"\"\n",
        "    print(f\"{'='*70}\\nPhase 1: Data Loading\\n{'='*70}\")\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"File not found: {file_path}. Please run feature extraction first.\")\n",
        "\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Drop duplicates\n",
        "    initial_len = len(df)\n",
        "    df = df.drop_duplicates()\n",
        "    if len(df) < initial_len:\n",
        "        print(f\"Removed {initial_len - len(df)} duplicate rows.\")\n",
        "\n",
        "    # Drop NaNs\n",
        "    df = df.dropna()\n",
        "\n",
        "    print(f\"✓ Dataset loaded: {len(df)} samples across {df['label'].nunique()} Maqam classes.\")\n",
        "    return df\n",
        "\n",
        "def split_data_stratified(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Performs a standard stratified split to maintain class balance.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*70}\\nPhase 2: Stratified Data Splitting\\n{'='*70}\")\n",
        "\n",
        "    # Stratify by 'label'\n",
        "    train_df, test_df = train_test_split(\n",
        "        df,\n",
        "        test_size=(1 - CFG.train_ratio),\n",
        "        stratify=df['label'],\n",
        "        random_state=CFG.seed\n",
        "    )\n",
        "\n",
        "    print(f\"Training set: {len(train_df)} samples\")\n",
        "    print(f\"Test set:     {len(test_df)} samples\")\n",
        "\n",
        "    # verify\n",
        "    print(\"\\nClass distribution (Top 5):\")\n",
        "    print(train_df['label'].value_counts(normalize=True).head().to_string())\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "def get_feature_columns(df: pd.DataFrame) -> List[str]:\n",
        "    \"\"\"Extract numeric feature columns excluding metadata.\"\"\"\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    return [col for col in numeric_cols if col not in CFG.columns_to_exclude]\n",
        "\n",
        "# 2. VISUALIZATION\n",
        "class EDAPlotter:\n",
        "    @staticmethod\n",
        "    def plot_class_balance(train_df: pd.DataFrame, test_df: pd.DataFrame):\n",
        "        print(\"Generating Figure 1: Class Balance...\")\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "        # Training\n",
        "        train_counts = train_df['label'].value_counts()\n",
        "        sns.barplot(x=train_counts.index, y=train_counts.values, ax=axes[0], palette='viridis')\n",
        "        axes[0].set_title(f\"Training Distribution (N={len(train_df)})\", fontweight='bold')\n",
        "        axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # Test\n",
        "        test_counts = test_df['label'].value_counts()\n",
        "        sns.barplot(x=test_counts.index, y=test_counts.values, ax=axes[1], palette='magma')\n",
        "        axes[1].set_title(f\"Test Distribution (N={len(test_df)})\", fontweight='bold')\n",
        "        axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{CFG.figure_dir}/Fig1_Class_Distribution.png', dpi=CFG.figure_dpi)\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_melodic_fingerprint(train_df: pd.DataFrame):\n",
        "        print(\"Generating Figure 2: Melodic Fingerprint (Chroma)...\")\n",
        "        chroma_cols = [c for c in train_df.columns if 'chroma_mean' in c]\n",
        "        if not chroma_cols: return\n",
        "\n",
        "        # Sort columns to ensure 0-11 or 0-23 order\n",
        "        chroma_cols.sort(key=lambda x: int(x.split('_')[-1]))\n",
        "\n",
        "        maqam_profiles = train_df[chroma_cols + ['label']].groupby('label').mean()\n",
        "\n",
        "        plt.figure(figsize=(14, 6))\n",
        "        sns.heatmap(maqam_profiles, cmap='magma', linewidths=0.5)\n",
        "        plt.title(\"Mean Chroma Profile (Quarter-Tone Bins)\", fontweight='bold')\n",
        "        plt.xlabel(\"Chroma Bin Index\")\n",
        "        plt.ylabel(\"Maqam\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{CFG.figure_dir}/Fig2_Melodic_Fingerprint.png', dpi=CFG.figure_dpi)\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_tsne_manifold(train_df: pd.DataFrame):\n",
        "        print(\"Generating Figure 3: t-SNE Manifold...\")\n",
        "        feature_cols = get_feature_columns(train_df)\n",
        "        if len(feature_cols) < 2: return\n",
        "\n",
        "        if len(train_df) > 5000:\n",
        "            plot_df = train_df.sample(5000, random_state=CFG.seed)\n",
        "        else:\n",
        "            plot_df = train_df.copy()\n",
        "\n",
        "        X = plot_df[feature_cols].fillna(0)\n",
        "        X_scaled = StandardScaler().fit_transform(X)\n",
        "\n",
        "        tsne = TSNE(n_components=2, random_state=CFG.seed,\n",
        "                    perplexity=CFG.tsne_perplexity, n_iter=CFG.tsne_n_iter, n_jobs=-1)\n",
        "\n",
        "        X_embedded = tsne.fit_transform(X_scaled)\n",
        "\n",
        "        tsne_df = pd.DataFrame(X_embedded, columns=['Dim1', 'Dim2'])\n",
        "        tsne_df['Maqam'] = plot_df['label'].values\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.scatterplot(data=tsne_df, x='Dim1', y='Dim2', hue='Maqam', palette='bright', alpha=0.7, s=40)\n",
        "        plt.title(\"t-SNE Projection of Acoustic Features\", fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{CFG.figure_dir}/Fig3_tSNE_Manifold.png', dpi=CFG.figure_dpi)\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_correlation_matrix(train_df: pd.DataFrame):\n",
        "        print(\"Generating Figure 4: Feature Correlations (Square)...\")\n",
        "\n",
        "        subset_cols = []\n",
        "        # Take first 3 of each type\n",
        "        for prefix in ['mfcc_mean', 'chroma_mean', 'contrast_mean']:\n",
        "            cols = [c for c in train_df.columns if prefix in c]\n",
        "            subset_cols.extend(cols[:3])\n",
        "\n",
        "        # Add physics-based features\n",
        "        spec_features = ['zcr_mean', 'rms_mean']\n",
        "        subset_cols.extend([c for c in spec_features if c in train_df.columns])\n",
        "\n",
        "        if len(subset_cols) < 2: return\n",
        "\n",
        "        corr = train_df[subset_cols].corr()\n",
        "        # mask = np.triu(np.ones_like(corr, dtype=bool)) # REMOVED MASK\n",
        "\n",
        "        plt.figure(figsize=(12, 10))\n",
        "\n",
        "        sns.heatmap(\n",
        "            corr,\n",
        "            # mask=mask, # REMOVED MASK ARGUMENT\n",
        "            cmap='coolwarm',\n",
        "            center=0,\n",
        "            annot=True,\n",
        "            fmt=\".2f\",\n",
        "            square=True,\n",
        "            cbar_kws={\"shrink\": 0.8},\n",
        "            annot_kws={\"size\": 10}\n",
        "        )\n",
        "\n",
        "        plt.title(\"Feature Correlation Matrix (Subset)\", fontweight='bold', pad=20)\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.yticks(rotation=0)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{CFG.figure_dir}/Fig4_Correlation_Matrix.png', dpi=CFG.figure_dpi, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "# 3. PIPELINE RUNNER\n",
        "def run_eda_pipeline():\n",
        "    try:\n",
        "        print(\"=\" * 70)\n",
        "        print(\"MAQAM EDA PIPELINE (Standard Stratified)\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # 1. Load\n",
        "        df = load_and_clean_data(CFG.input_csv)\n",
        "\n",
        "        # 2. Split\n",
        "        train_df, test_df = split_data_stratified(df)\n",
        "\n",
        "        # 3. Save Processed\n",
        "        train_df.to_csv(\"train_split.csv\", index=False)\n",
        "        test_df.to_csv(\"test_split.csv\", index=False)\n",
        "        print(\"✓ Saved train_split.csv and test_split.csv\")\n",
        "\n",
        "        # 4. Plot\n",
        "        print(f\"\\n{'='*70}\\nPhase 3: Generating Visuals\\n{'='*70}\")\n",
        "        plotter = EDAPlotter()\n",
        "        plotter.plot_class_balance(train_df, test_df)\n",
        "        plotter.plot_melodic_fingerprint(train_df)\n",
        "        plotter.plot_tsne_manifold(train_df)\n",
        "        plotter.plot_correlation_matrix(train_df)\n",
        "\n",
        "        print(f\"\\nPipeline Finished. Figures saved in '{CFG.figure_dir}/'\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nERROR: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_eda_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxSji8uDw7nd",
        "outputId": "49918061-908c-44c6-deb3-8283070cbdf0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "MAQAM EDA PIPELINE (Standard Stratified)\n",
            "======================================================================\n",
            "======================================================================\n",
            "Phase 1: Data Loading\n",
            "======================================================================\n",
            "✓ Dataset loaded: 924 samples across 8 Maqam classes.\n",
            "\n",
            "======================================================================\n",
            "Phase 2: Stratified Data Splitting\n",
            "======================================================================\n",
            "Training set: 739 samples\n",
            "Test set:     185 samples\n",
            "\n",
            "Class distribution (Top 5):\n",
            "label\n",
            "Hijaz       0.147497\n",
            "Rast        0.144790\n",
            "Saba        0.123139\n",
            "Nahawand    0.121786\n",
            "Bayat       0.121786\n",
            "✓ Saved train_split.csv and test_split.csv\n",
            "\n",
            "======================================================================\n",
            "Phase 3: Generating Visuals\n",
            "======================================================================\n",
            "Generating Figure 1: Class Balance...\n",
            "Generating Figure 2: Melodic Fingerprint (Chroma)...\n",
            "Generating Figure 3: t-SNE Manifold...\n",
            "Generating Figure 4: Feature Correlations (Square)...\n",
            "\n",
            "Pipeline Finished. Figures saved in 'paper_figures/'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import os\n",
        "import joblib\n",
        "import shap\n",
        "import gc   # Added for garbage collection\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import GridSearchCV, learning_curve, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, label_binarize\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                             roc_curve, auc, confusion_matrix)\n",
        "\n",
        "# PLOTTING CONFIGURATION\n",
        "plt.rcParams.update({\n",
        "    'font.size': 12,\n",
        "    'font.family': 'sans-serif',\n",
        "    'axes.labelsize': 14, 'axes.titlesize': 16,\n",
        "    'legend.fontsize': 11, 'xtick.labelsize': 11, 'ytick.labelsize': 11,\n",
        "    'figure.dpi': 300, 'savefig.dpi': 300, 'axes.grid': True, 'grid.alpha': 0.3\n",
        "})\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# CONFIG\n",
        "class Config:\n",
        "    train_path = \"train_split.csv\"\n",
        "    test_path = \"test_split.csv\"\n",
        "    out_dir = \"paper_results\"\n",
        "    seed = 42\n",
        "    cv_folds = 10\n",
        "    n_jobs = 1\n",
        "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
        "\n",
        "    # Explainability settings\n",
        "    shap_background_samples = 10\n",
        "\n",
        "CFG = Config()\n",
        "Path(CFG.out_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 1. DATA LOADING\n",
        "def load_data():\n",
        "    print(\"Loading data...\")\n",
        "    train = pd.read_csv(CFG.train_path)\n",
        "    test = pd.read_csv(CFG.test_path)\n",
        "\n",
        "    meta_cols = ['label', 'filename', 'filepath', 'track_id', 'recording_id']\n",
        "    X_train = train.drop(columns=meta_cols, errors='ignore')\n",
        "    y_train = train['label']\n",
        "    X_test = test.drop(columns=meta_cols, errors='ignore')\n",
        "    y_test = test['label']\n",
        "\n",
        "    le = LabelEncoder()\n",
        "    y_train = le.fit_transform(y_train)\n",
        "    y_test = le.transform(y_test)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_s = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
        "    X_test_s = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
        "\n",
        "    return X_train_s, y_train, X_test_s, y_test, le\n",
        "\n",
        "# 2. MODEL TRAINING\n",
        "def train_models(X_train, y_train):\n",
        "    print(\"Training models...\")\n",
        "\n",
        "    models = {\n",
        "        'Logistic Regression': LogisticRegression(random_state=CFG.seed, max_iter=2000),\n",
        "        'KNN': KNeighborsClassifier(),\n",
        "        'Random Forest': RandomForestClassifier(random_state=CFG.seed),\n",
        "        'SVM': SVC(probability=True, random_state=CFG.seed, kernel='rbf', class_weight='balanced')\n",
        "    }\n",
        "\n",
        "    grids = {\n",
        "        'Logistic Regression': {'C': [0.1, 1, 10]},\n",
        "        'KNN': {'n_neighbors': [5, 9, 15]},\n",
        "        'Random Forest': {'n_estimators': [100, 200], 'max_depth': [10, 20]},\n",
        "        'SVM': {'C': [1, 10], 'gamma': ['scale', 0.01]}\n",
        "    }\n",
        "\n",
        "    best_models = {}\n",
        "    cv_scores = {}\n",
        "    best_params = {}\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=CFG.cv_folds, shuffle=True, random_state=CFG.seed)\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"  Optimizing {name}...\")\n",
        "        gs = GridSearchCV(model, grids[name], cv=cv, scoring='accuracy', n_jobs=CFG.n_jobs)\n",
        "        gs.fit(X_train, y_train)\n",
        "\n",
        "        best_models[name] = gs.best_estimator_\n",
        "        cv_scores[name] = gs.best_score_\n",
        "        best_params[name] = gs.best_params_\n",
        "\n",
        "    return best_models, cv_scores, best_params\n",
        "\n",
        "# 3. EVALUATION\n",
        "def evaluate(models, cv_scores, X_test, y_test):\n",
        "    \"\"\"Calculate aggregate metrics.\"\"\"\n",
        "    results = []\n",
        "    for name, model in models.items():\n",
        "        p = model.predict(X_test)\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'CV Accuracy': cv_scores[name],\n",
        "            'Test Accuracy': accuracy_score(y_test, p),\n",
        "            'Precision': precision_score(y_test, p, average='weighted', zero_division=0),\n",
        "            'Recall': recall_score(y_test, p, average='weighted', zero_division=0),\n",
        "            'F1 Score': f1_score(y_test, p, average='weighted', zero_division=0)\n",
        "        })\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# 4. VISUALIZATION\n",
        "def plot_metrics(df):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # 1. Filter OUT CV Accuracy\n",
        "    df_plot = df.drop(columns=['CV Accuracy'])\n",
        "\n",
        "    # 2. Rename 'Test Accuracy' to 'Accuracy'\n",
        "    df_plot = df_plot.rename(columns={'Test Accuracy': 'Accuracy'})\n",
        "\n",
        "    df_melt = df_plot.melt(id_vars=\"Model\", var_name=\"Metric\", value_name=\"Score\")\n",
        "\n",
        "    ax = sns.barplot(data=df_melt, x=\"Metric\", y=\"Score\", hue=\"Model\", palette=\"viridis\")\n",
        "\n",
        "    for c in ax.containers:\n",
        "        # Rotation 0 for horizontal numbers\n",
        "        ax.bar_label(c, fmt='%.2f', padding=3, fontsize=9, rotation=0)\n",
        "\n",
        "    plt.legend(bbox_to_anchor=(1.01, 1), loc='upper left')\n",
        "    plt.ylim(0, 1.25)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{CFG.out_dir}/Fig1_Metrics.png\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_combined_roc(models, X_test, y_test, le):\n",
        "    plt.figure(figsize=(9, 7))\n",
        "    y_bin = label_binarize(y_test, classes=range(len(le.classes_)))\n",
        "\n",
        "    for (name, model), color in zip(models.items(), CFG.colors):\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            probs = model.predict_proba(X_test)\n",
        "            fpr, tpr, _ = roc_curve(y_bin.ravel(), probs.ravel())\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            plt.plot(fpr, tpr, label=f'{name} (AUC={roc_auc:.2f})', color=color, lw=2.5)\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=1.5)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{CFG.out_dir}/Fig2_ROC.png\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_learning_curves(models, X_train, y_train):\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, (name, model) in enumerate(models.items()):\n",
        "        ax = axes[i]\n",
        "        # 10 points for smoother curves\n",
        "        sizes, train_scores, test_scores = learning_curve(\n",
        "            model, X_train, y_train, cv=CFG.cv_folds, n_jobs=CFG.n_jobs,\n",
        "            train_sizes=np.linspace(0.1, 1.0, 10), scoring='accuracy'\n",
        "        )\n",
        "\n",
        "        train_mean = np.mean(train_scores, axis=1)\n",
        "        train_std = np.std(train_scores, axis=1)\n",
        "        test_mean = np.mean(test_scores, axis=1)\n",
        "        test_std = np.std(test_scores, axis=1)\n",
        "\n",
        "        ax.plot(sizes, train_mean, 'o-', color=CFG.colors[0], label='Train')\n",
        "        ax.plot(sizes, test_mean, 's-', color=CFG.colors[1], label='CV (Validation)')\n",
        "\n",
        "        ax.fill_between(sizes, test_mean - test_std, test_mean + test_std,\n",
        "                        alpha=0.15, color=CFG.colors[1])\n",
        "\n",
        "        ax.set_title(name, fontweight='bold')\n",
        "        ax.set_ylim(0.4, 1.05)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        if i==0: ax.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{CFG.out_dir}/Fig3_LearningCurves.png\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_loss_curves(models, X_train, y_train):\n",
        "    print(\"Generating Loss Curves...\")\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, (name, model) in enumerate(models.items()):\n",
        "        ax = axes[i]\n",
        "        # 10 points for smoother curves\n",
        "        sizes, train_scores, test_scores = learning_curve(\n",
        "            model, X_train, y_train, cv=CFG.cv_folds, n_jobs=CFG.n_jobs,\n",
        "            train_sizes=np.linspace(0.1, 1.0, 10), scoring='neg_log_loss'\n",
        "        )\n",
        "\n",
        "        train_loss = -np.mean(train_scores, axis=1)\n",
        "        test_loss = -np.mean(test_scores, axis=1)\n",
        "\n",
        "        ax.plot(sizes, train_loss, 'o-', color='#d62728', label='Train Loss')\n",
        "        ax.plot(sizes, test_loss, 's-', color='#2ca02c', label='Validation Loss')\n",
        "\n",
        "        ax.set_title(name, fontweight='bold')\n",
        "        ax.set_xlabel(\"Training Examples\")\n",
        "        ax.set_ylabel(\"Log Loss\")\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        if i==0: ax.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{CFG.out_dir}/Fig4_LossCurves.png\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrices(models, X_test, y_test, le):\n",
        "    \"\"\"Generates a 2x2 grid of confusion matrices.\"\"\"\n",
        "    print(\"Generating Confusion Matrices...\")\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, (name, model) in enumerate(models.items()):\n",
        "        ax = axes[i]\n",
        "        y_pred = model.predict(X_test)\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        # Plot heatmap\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "                    xticklabels=le.classes_, yticklabels=le.classes_, cbar=False)\n",
        "\n",
        "        ax.set_title(name, fontweight='bold')\n",
        "        ax.set_xlabel('Predicted Label')\n",
        "        ax.set_ylabel('True Label')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{CFG.out_dir}/Fig6_ConfusionMatrices.png\")\n",
        "    plt.close()\n",
        "\n",
        "# 5. EXPLAINABILITY (SHAP)\n",
        "def aggregate_shap_data(shap_values, X_df):\n",
        "    df_shap = pd.DataFrame(shap_values, columns=X_df.columns)\n",
        "    col_to_group = {}\n",
        "    for col in X_df.columns:\n",
        "        parts = col.rsplit('_', 1)\n",
        "        if len(parts) > 1 and parts[1].isdigit():\n",
        "            col_to_group[col] = parts[0]\n",
        "        else:\n",
        "            col_to_group[col] = col\n",
        "\n",
        "    df_shap_grouped = df_shap.groupby(col_to_group, axis=1).sum()\n",
        "    df_X_grouped = X_df.groupby(col_to_group, axis=1).mean()\n",
        "    return df_shap_grouped.values, df_X_grouped\n",
        "\n",
        "def explain_models(models, X_train, X_test):\n",
        "    \"\"\"\n",
        "    2x2 SHAP Plot on FULL Test Set (Legend Removed)\n",
        "    \"\"\"\n",
        "    print(f\"\\nGenerating SHAP Explanations on FULL Test Set ({len(X_test)} samples)...\")\n",
        "\n",
        "    background_summary = shap.kmeans(X_train, CFG.shap_background_samples)\n",
        "\n",
        "    # 2x2 Grid Layout\n",
        "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 14))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, (name, model) in enumerate(models.items()):\n",
        "        print(f\"  Calculating SHAP for {name}...\")\n",
        "        plt.sca(axes[i])\n",
        "\n",
        "        try:\n",
        "            shap_values_raw = None\n",
        "\n",
        "            if \"Random Forest\" in name:\n",
        "                explainer = shap.TreeExplainer(model)\n",
        "                shap_values_raw = explainer.shap_values(X_test)\n",
        "\n",
        "            elif \"Logistic Regression\" in name:\n",
        "                explainer = shap.LinearExplainer(model, X_train)\n",
        "                shap_values_raw = explainer.shap_values(X_test)\n",
        "\n",
        "            else:\n",
        "                f = model.predict_proba if hasattr(model, 'predict_proba') else model.predict\n",
        "                explainer = shap.KernelExplainer(f, background_summary)\n",
        "                shap_values_raw = explainer.shap_values(X_test, silent=True)\n",
        "\n",
        "            if isinstance(shap_values_raw, list):\n",
        "                vals_to_plot = shap_values_raw[1]\n",
        "            elif hasattr(shap_values_raw, \"values\") and len(shap_values_raw.values.shape) == 3:\n",
        "                vals_to_plot = shap_values_raw.values[:, :, 1]\n",
        "            elif len(np.array(shap_values_raw).shape) == 3:\n",
        "                vals_to_plot = np.array(shap_values_raw)[:, :, 1]\n",
        "            else:\n",
        "                vals_to_plot = shap_values_raw\n",
        "\n",
        "            grouped_shap, grouped_X = aggregate_shap_data(vals_to_plot, X_test)\n",
        "\n",
        "            shap.summary_plot(\n",
        "                grouped_shap,\n",
        "                grouped_X,\n",
        "                feature_names=grouped_X.columns,\n",
        "                show=False,\n",
        "                plot_type=\"dot\",\n",
        "                max_display=20,\n",
        "                color_bar=False # REMOVED LEGEND\n",
        "            )\n",
        "\n",
        "            axes[i].set_title(f\"{name}\", fontsize=18, fontweight='bold', pad=10)\n",
        "            axes[i].tick_params(axis='y', labelsize=12)\n",
        "            axes[i].set_xlabel(\"SHAP value\", fontsize=12)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Error explaining {name}: {e}\")\n",
        "            axes[i].text(0.5, 0.5, f\"Error: {str(e)}\", ha='center')\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "    plt.subplots_adjust(wspace=0.4, hspace=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{CFG.out_dir}/Fig5_SHAP_Combined.png\", bbox_inches='tight', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "# MAIN\n",
        "if __name__ == \"__main__\":\n",
        "    X_train, y_train, X_test, y_test, le = load_data()\n",
        "\n",
        "    models, cv_scores, best_params = train_models(X_train, y_train)\n",
        "\n",
        "    print(\"\\nBest Hyperparameters found:\")\n",
        "    param_df = pd.Series(best_params, name='Best_Params').to_frame()\n",
        "    print(param_df)\n",
        "    param_df.to_csv(f\"{CFG.out_dir}/hyperparams.csv\")\n",
        "\n",
        "    metrics = evaluate(models, cv_scores, X_test, y_test)\n",
        "    print(\"\\nResults:\\n\", metrics)\n",
        "    metrics.to_csv(f\"{CFG.out_dir}/metrics.csv\", index=False)\n",
        "\n",
        "    print(\"\\nGenerating Figures...\")\n",
        "    plot_metrics(metrics)\n",
        "    plot_combined_roc(models, X_test, y_test, le)\n",
        "    plot_learning_curves(models, X_train, y_train)\n",
        "    plot_loss_curves(models, X_train, y_train)\n",
        "    plot_confusion_matrices(models, X_test, y_test, le) # New function added here\n",
        "\n",
        "    explain_models(models, X_train, X_test)\n",
        "\n",
        "    print(f\"Done. Results saved to {CFG.out_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icklu87ex0GL",
        "outputId": "64d51e50-3665-4818-9612-0bd2d69b9472"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Training models...\n",
            "  Optimizing Logistic Regression...\n",
            "  Optimizing KNN...\n",
            "  Optimizing Random Forest...\n",
            "  Optimizing SVM...\n",
            "\n",
            "Best Hyperparameters found:\n",
            "                                                Best_Params\n",
            "Logistic Regression                               {'C': 10}\n",
            "KNN                                      {'n_neighbors': 5}\n",
            "Random Forest        {'max_depth': 20, 'n_estimators': 100}\n",
            "SVM                                {'C': 10, 'gamma': 0.01}\n",
            "\n",
            "Results:\n",
            "                  Model  CV Accuracy  Test Accuracy  Precision    Recall  \\\n",
            "0  Logistic Regression     0.884969       0.875676   0.876543  0.875676   \n",
            "1                  KNN     0.918752       0.918919   0.932102  0.918919   \n",
            "2        Random Forest     0.920141       0.924324   0.927203  0.924324   \n",
            "3                  SVM     0.955331       0.972973   0.973230  0.972973   \n",
            "\n",
            "   F1 Score  \n",
            "0  0.874262  \n",
            "1  0.920889  \n",
            "2  0.924560  \n",
            "3  0.972988  \n",
            "\n",
            "Generating Figures...\n",
            "Generating Loss Curves...\n",
            "Generating Confusion Matrices...\n",
            "\n",
            "Generating SHAP Explanations on FULL Test Set (185 samples)...\n",
            "  Calculating SHAP for Logistic Regression...\n",
            "  Calculating SHAP for KNN...\n",
            "  Calculating SHAP for Random Forest...\n",
            "  Calculating SHAP for SVM...\n",
            "Done. Results saved to paper_results\n"
          ]
        }
      ]
    }
  ]
}